{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        pass\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nfrom random import  shuffle\nimport os\nimport tensorflow as tf\nfrom random import shuffle","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_SIZE=224\nX=[]\nY=[]\ntraining_data=[]\ntest_data=[]\nX_t=[]\nY_t=[]","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path=\"/kaggle/input/dogs-cats-images/dataset/training_set/\"\nfor i in os.listdir(path+'cats/'):\n    img=cv2.imread(path+'cats/'+i)\n    img=cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n    training_data.append(tuple([img,1]))\n    #X.append(img)\n    #Y.append(1)\nfor i in os.listdir(path+'dogs/'):\n    img=cv2.imread(path+'dogs/'+i)\n    img=cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n    training_data.append(tuple([img,0]))\n    #X.append(img)\n    #Y.append(0)\n\nshuffle(training_data)\nfor features,labels in training_data:\n    X.append(features)\n    Y.append(labels)\n\ndel training_data\n\npath=\"/kaggle/input/dogs-cats-images/dataset/test_set/\"\nfor i in os.listdir(path+'cats/'):\n    img=cv2.imread(path+'cats/'+i)\n    img=cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n    test_data.append(tuple([img,1]))\n    #X.append(img)\n    #Y.append(1)\nfor i in os.listdir(path+'dogs/'):\n    img=cv2.imread(path+'dogs/'+i)\n    img=cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n    test_data.append(tuple([img,0]))\n    #X.append(img)\n    #Y.append(0)\n\nshuffle(test_data)\nfor features,labels in test_data:\n    X_t.append(features)\n    Y_t.append(labels)\n\ndel test_data\n","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=np.array(X)\n#X=X/225.0\nY=np.array(Y)\nX=np.array(X).reshape(-1,IMG_SIZE,IMG_SIZE,3)\nX.shape\n\nX_t=np.array(X_t)\n#X_t=X-t/225.0\nY_t=np.array(Y_t)\nX_t=np.array(X_t).reshape(-1,IMG_SIZE,IMG_SIZE,3)\nX_t.shape","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"(2000, 224, 224, 3)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class myCallBack(tf.keras.callbacks.Callback):\n    def on_epoch_end(self,epoch,logs={}):\n        if(logs.get('accuracy') > 0.95):\n            self.model.stop_training = True\n\ncallback=myCallBack()\n        ","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=tf.keras.models.Sequential()\n\nmodel.add(tf.keras.layers.Conv2D(64,(3,3), input_shape=X.shape[1:],activation='relu'))\nmodel.add(tf.keras.layers.MaxPooling2D(2,2))\n\nmodel.add(tf.keras.layers.Conv2D(64,(3,3),activation='relu'))\nmodel.add(tf.keras.layers.MaxPooling2D(2,2))\n\nmodel.add(tf.keras.layers.Conv2D(64,(3,3),activation='relu'))\nmodel.add(tf.keras.layers.MaxPooling2D(2,2))\n\nmodel.add(tf.keras.layers.Conv2D(64,(3,3),activation='relu'))\nmodel.add(tf.keras.layers.MaxPooling2D(2,2))\n\nmodel.add(tf.keras.layers.Conv2D(64,(3,3),activation='relu'))\nmodel.add(tf.keras.layers.MaxPooling2D(2,2))\n\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(256,\n                                activation='relu',\n                                kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n#model.add(tf.keras.layers.Dropout(0.25))\nmodel.add(tf.keras.layers.Dense(256,activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n#model.add(tf.keras.layers.Dropout(0.25))\nmodel.add(tf.keras.layers.Dense(256,activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.01)))\nmodel.add(tf.keras.layers.Dense(2,activation='softmax'))\n\nmodel.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n\n\n\nmodel.fit(X,Y,epochs=30,validation_data=(X_t,Y_t),callbacks=[callback])","execution_count":12,"outputs":[{"output_type":"stream","text":"Epoch 1/30\n250/250 [==============================] - 9s 36ms/step - loss: 5.1580 - accuracy: 0.5351 - val_loss: 3.3609 - val_accuracy: 0.5990\nEpoch 2/30\n250/250 [==============================] - 9s 34ms/step - loss: 2.7390 - accuracy: 0.6309 - val_loss: 2.2674 - val_accuracy: 0.6105\nEpoch 3/30\n250/250 [==============================] - 9s 34ms/step - loss: 1.9220 - accuracy: 0.6636 - val_loss: 1.6777 - val_accuracy: 0.6460\nEpoch 4/30\n250/250 [==============================] - 9s 34ms/step - loss: 1.4285 - accuracy: 0.6975 - val_loss: 1.2495 - val_accuracy: 0.7140\nEpoch 5/30\n250/250 [==============================] - 9s 35ms/step - loss: 1.0921 - accuracy: 0.7414 - val_loss: 0.9968 - val_accuracy: 0.7435\nEpoch 6/30\n250/250 [==============================] - 9s 34ms/step - loss: 0.8669 - accuracy: 0.7729 - val_loss: 0.7917 - val_accuracy: 0.7780\nEpoch 7/30\n250/250 [==============================] - 9s 34ms/step - loss: 0.7197 - accuracy: 0.7930 - val_loss: 0.7121 - val_accuracy: 0.7700\nEpoch 8/30\n250/250 [==============================] - 8s 34ms/step - loss: 0.5885 - accuracy: 0.8230 - val_loss: 0.6152 - val_accuracy: 0.7935\nEpoch 9/30\n250/250 [==============================] - 9s 34ms/step - loss: 0.5021 - accuracy: 0.8407 - val_loss: 0.5463 - val_accuracy: 0.8160\nEpoch 10/30\n250/250 [==============================] - 8s 34ms/step - loss: 0.4303 - accuracy: 0.8627 - val_loss: 0.5213 - val_accuracy: 0.8075\nEpoch 11/30\n250/250 [==============================] - 9s 34ms/step - loss: 0.3705 - accuracy: 0.8774 - val_loss: 0.5010 - val_accuracy: 0.8115\nEpoch 12/30\n250/250 [==============================] - 9s 35ms/step - loss: 0.3180 - accuracy: 0.9001 - val_loss: 0.5355 - val_accuracy: 0.8065\nEpoch 13/30\n250/250 [==============================] - 9s 34ms/step - loss: 0.2770 - accuracy: 0.9143 - val_loss: 0.5143 - val_accuracy: 0.8300\nEpoch 14/30\n250/250 [==============================] - 8s 34ms/step - loss: 0.2427 - accuracy: 0.9290 - val_loss: 0.5279 - val_accuracy: 0.8090\nEpoch 15/30\n250/250 [==============================] - 8s 34ms/step - loss: 0.2166 - accuracy: 0.9360 - val_loss: 0.6430 - val_accuracy: 0.7885\nEpoch 16/30\n250/250 [==============================] - 9s 34ms/step - loss: 0.2067 - accuracy: 0.9408 - val_loss: 0.6273 - val_accuracy: 0.8130\nEpoch 17/30\n250/250 [==============================] - 8s 34ms/step - loss: 0.1804 - accuracy: 0.9516 - val_loss: 0.6761 - val_accuracy: 0.8070\n","name":"stdout"},{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f7808fbaf50>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('saved_model.h5')","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}